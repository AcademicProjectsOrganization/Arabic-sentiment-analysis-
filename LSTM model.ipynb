{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7149868,"sourceType":"datasetVersion","datasetId":4128014},{"sourceId":7156635,"sourceType":"datasetVersion","datasetId":4133082}],"dockerImageVersionId":30615,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nimport nltk\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.backend import clear_session\nfrom keras.models import load_model\n\n\ntrain_data = pd.read_excel(\"/kaggle/input/nlp-project/train.xlsx\")\n\ntrain_data.info()  \n\ntrain_data.columns = ['review_description','rating']\ntrain_data.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-19T10:49:55.126345Z","iopub.execute_input":"2023-12-19T10:49:55.126785Z","iopub.status.idle":"2023-12-19T10:50:14.437821Z","shell.execute_reply.started":"2023-12-19T10:49:55.126749Z","shell.execute_reply":"2023-12-19T10:50:14.436790Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 32036 entries, 0 to 32035\nData columns (total 2 columns):\n #   Column              Non-Null Count  Dtype \n---  ------              --------------  ----- \n 0   review_description  32036 non-null  object\n 1   rating              32036 non-null  int64 \ndtypes: int64(1), object(1)\nmemory usage: 500.7+ KB\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"                                  review_description  rating\n0  شركه زباله و سواقين بتبرشم و مفيش حتي رقم للشك...      -1\n1  خدمة الدفع عن طريق الكي نت توقفت عندي اصبح فقط...       1\n2  تطبيق غبي و جاري حذفه ، عاملين اكواد خصم و لما...      -1\n3  فعلا تطبيق ممتاز بس لو فى امكانية يتيح لمستخدم...       1\n4  سيء جدا ، اسعار رسوم التوصيل لا تمت للواقع ب ص...      -1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_description</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>شركه زباله و سواقين بتبرشم و مفيش حتي رقم للشك...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>خدمة الدفع عن طريق الكي نت توقفت عندي اصبح فقط...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>تطبيق غبي و جاري حذفه ، عاملين اكواد خصم و لما...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>فعلا تطبيق ممتاز بس لو فى امكانية يتيح لمستخدم...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>سيء جدا ، اسعار رسوم التوصيل لا تمت للواقع ب ص...</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# here we make preprocessing on the data\nimport re\n\nsearch = [\"أ\",\"إ\",\"آ\",\"ة\",\"_\",\"-\",\"/\",\".\",\"،\",\" و \",\" يا \",'\"',\"ـ\",\"'\",\"ى\",\n              \"\\\\\",'\\n', '\\t','\"','?','؟','!']\nreplace = [\"ا\",\"ا\",\"ا\",\"ه\",\" \",\" \",\"\",\"\",\"\",\" و\",\" يا\",\n               \"\",\"\",\"\",\"ي\",\"\",' ', ' ',' ',' ? ',' ؟ ', ' ! ']\ndef process_review(review):\n    processed_review = re.sub(r\"[^\\w\\s]\", '', review)# accept all things accept any word,digit,white space and replace with empty string\n    processed_review = re.sub(r\"[a-zA-Z]\", '', processed_review) # here I remove all english lettters\n    for i in range(0, len(search)):\n        processed_review = processed_review.replace(search[i], replace[i])\n    processed_review = re.sub(r\"\\d+\", '', processed_review)\n    processed_review = re.sub(r\"\\n\", '', processed_review)# here remove new line\n    processed_review = re.sub(r\"\\s+\", ' ', processed_review)# here remove white spaces\n    processed_review = re.sub(r'(.)\\1+', r'\\1', processed_review)# here if there are any repeate in any character replace it with one occurance\n    \n    return processed_review.strip() # return review after precessed without any additional white space\n\ntrain_data['cleaned_text'] = train_data.review_description.apply(process_review)\n# train_data = train_data[train_data.cleaned_text != \"\"]\ntrain_data.head(10)\n ","metadata":{"execution":{"iopub.status.busy":"2023-12-19T10:50:14.439785Z","iopub.execute_input":"2023-12-19T10:50:14.440520Z","iopub.status.idle":"2023-12-19T10:50:15.288459Z","shell.execute_reply.started":"2023-12-19T10:50:14.440455Z","shell.execute_reply":"2023-12-19T10:50:15.287058Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                  review_description  rating  \\\n0  شركه زباله و سواقين بتبرشم و مفيش حتي رقم للشك...      -1   \n1  خدمة الدفع عن طريق الكي نت توقفت عندي اصبح فقط...       1   \n2  تطبيق غبي و جاري حذفه ، عاملين اكواد خصم و لما...      -1   \n3  فعلا تطبيق ممتاز بس لو فى امكانية يتيح لمستخدم...       1   \n4  سيء جدا ، اسعار رسوم التوصيل لا تمت للواقع ب ص...      -1   \n5  قعد عشرين سنة يدور على سائق بس اما عن توصيل ال...       0   \n6                                         احلئ تطبيق       1   \n7                                      رائع واو مدهش       1   \n8  مکو بس البحرین وعمان وغیرهه بس العراق مکو یعنی...      -1   \n9                    تطبيق جميل يستاهل الخمس نجوم👍👍👍       1   \n\n                                        cleaned_text  \n0  شركه زباله وسواقين بتبرشم ومفيش حتي رقم لشكاوي...  \n1  خدمه الدفع عن طريق الكي نت توقفت عندي اصبح فقط...  \n2  تطبيق غبي وجاري حذفه عاملين اكواد خصم ولما نست...  \n3  فعلا تطبيق متاز بس لو في امكانيه يتيح لمستخدم ...  \n4      سيء جدا اسعار رسوم التوصيل لا تمت لواقع ب صله  \n5  قعد عشرين سنه يدور علي سائق بس اما عن توصيل ال...  \n6                                         احلئ تطبيق  \n7                                      رائع واو مدهش  \n8  مکو بس البحرین وعمان وغیره بس العراق مکو یعنی ...  \n9                       تطبيق جميل يستاهل الخمس نجوم  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_description</th>\n      <th>rating</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>شركه زباله و سواقين بتبرشم و مفيش حتي رقم للشك...</td>\n      <td>-1</td>\n      <td>شركه زباله وسواقين بتبرشم ومفيش حتي رقم لشكاوي...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>خدمة الدفع عن طريق الكي نت توقفت عندي اصبح فقط...</td>\n      <td>1</td>\n      <td>خدمه الدفع عن طريق الكي نت توقفت عندي اصبح فقط...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>تطبيق غبي و جاري حذفه ، عاملين اكواد خصم و لما...</td>\n      <td>-1</td>\n      <td>تطبيق غبي وجاري حذفه عاملين اكواد خصم ولما نست...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>فعلا تطبيق ممتاز بس لو فى امكانية يتيح لمستخدم...</td>\n      <td>1</td>\n      <td>فعلا تطبيق متاز بس لو في امكانيه يتيح لمستخدم ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>سيء جدا ، اسعار رسوم التوصيل لا تمت للواقع ب ص...</td>\n      <td>-1</td>\n      <td>سيء جدا اسعار رسوم التوصيل لا تمت لواقع ب صله</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>قعد عشرين سنة يدور على سائق بس اما عن توصيل ال...</td>\n      <td>0</td>\n      <td>قعد عشرين سنه يدور علي سائق بس اما عن توصيل ال...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>احلئ تطبيق</td>\n      <td>1</td>\n      <td>احلئ تطبيق</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>رائع واو مدهش</td>\n      <td>1</td>\n      <td>رائع واو مدهش</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>مکو بس البحرین وعمان وغیرهه بس العراق مکو یعنی...</td>\n      <td>-1</td>\n      <td>مکو بس البحرین وعمان وغیره بس العراق مکو یعنی ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>تطبيق جميل يستاهل الخمس نجوم👍👍👍</td>\n      <td>1</td>\n      <td>تطبيق جميل يستاهل الخمس نجوم</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nX = train_data.cleaned_text.values #training paramter\nY = train_data['rating'].astype('int') #prediction paramter\n# Y = Y.clip(0, 1)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T10:50:15.289725Z","iopub.execute_input":"2023-12-19T10:50:15.290070Z","iopub.status.idle":"2023-12-19T10:50:15.297435Z","shell.execute_reply.started":"2023-12-19T10:50:15.290041Z","shell.execute_reply":"2023-12-19T10:50:15.296289Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from nltk.tokenize import WordPunctTokenizer \nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom nltk import word_tokenize  \ntokenizer = WordPunctTokenizer()\nX_tokenized = [word_tokenize(sentence.lower()) for sentence in X]\nword_index = {word: index + 1 for index, word in enumerate(set(word_tokenize(\" \".join(X))))}\nX_sequences = [[word_index.get(word, 0) for word in sentence] for sentence in X_tokenized]\nmaxlen = max(len(seq) for seq in X_sequences)\nprint(maxlen)\nX_padded = pad_sequences(X_sequences, padding='post', maxlen=maxlen)\nX=X_padded  \nprint(X)\nprint(\"Vocabulary size:\", len(word_index))\nprint(X.shape[1])\n# print(len(X))","metadata":{"execution":{"iopub.status.busy":"2023-12-19T10:50:15.300791Z","iopub.execute_input":"2023-12-19T10:50:15.301143Z","iopub.status.idle":"2023-12-19T10:50:20.730834Z","shell.execute_reply.started":"2023-12-19T10:50:15.301113Z","shell.execute_reply":"2023-12-19T10:50:20.729229Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"362\n[[10326  6131   226 ...     0     0     0]\n [20782  2596 19179 ...     0     0     0]\n [26136  2237 27874 ...     0     0     0]\n ...\n [29994 29479 26410 ...     0     0     0]\n [26136 26221 26396 ...     0     0     0]\n [29811 16509 20971 ...     0     0     0]]\nVocabulary size: 33372\n362\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\nY= label_encoder.fit_transform(Y)\nprint(Y)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T10:50:20.732527Z","iopub.execute_input":"2023-12-19T10:50:20.732957Z","iopub.status.idle":"2023-12-19T10:50:20.743766Z","shell.execute_reply.started":"2023-12-19T10:50:20.732922Z","shell.execute_reply":"2023-12-19T10:50:20.741806Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[0 2 0 ... 0 0 2]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, label_train, label_val = train_test_split(X , Y, test_size=0.4, random_state=42)\nX_val,X_test,label_val,label_test = train_test_split( X_val , label_val, test_size=0.5, random_state=42)\nprint(\"Training:\", len(X_train))\nprint(\"valadation\",len(X_val))\nprint(\"Testing: \", len(X_test))","metadata":{"execution":{"iopub.status.busy":"2023-12-19T10:50:20.745264Z","iopub.execute_input":"2023-12-19T10:50:20.745847Z","iopub.status.idle":"2023-12-19T10:50:20.824063Z","shell.execute_reply.started":"2023-12-19T10:50:20.745783Z","shell.execute_reply":"2023-12-19T10:50:20.822936Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Training: 19221\nvaladation 6407\nTesting:  6408\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":" \nembedding_dim = 100\ndropout = 0.5\nopt = 'adam'\nclear_session()\nmodel = Sequential()\nmodel.add(layers.Embedding(input_dim=33373, \n                           output_dim=362, \n                           input_length=362))\nmodel.add(layers.Bidirectional(layers.LSTM(100, dropout=0.5, \n                                           recurrent_dropout=0.5, \n                                           return_sequences=True)))\nmodel.add(layers.GlobalMaxPool1D())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(dropout))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dropout(dropout))\nmodel.add(layers.Dense(32, activation='relu'))\nmodel.add(layers.Dropout(dropout))\nmodel.add(layers.Dense(3, activation='softmax'))\n\nmodel.compile(optimizer=opt, \n              loss='sparse_categorical_crossentropy', \n              metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T10:50:20.825842Z","iopub.execute_input":"2023-12-19T10:50:20.826248Z","iopub.status.idle":"2023-12-19T10:50:21.664860Z","shell.execute_reply.started":"2023-12-19T10:50:20.826210Z","shell.execute_reply":"2023-12-19T10:50:21.663636Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 362, 362)          12081026  \n                                                                 \n bidirectional (Bidirection  (None, 362, 200)          370400    \n al)                                                             \n                                                                 \n global_max_pooling1d (Glob  (None, 200)               0         \n alMaxPooling1D)                                                 \n                                                                 \n dense (Dense)               (None, 128)               25728     \n                                                                 \n dropout (Dropout)           (None, 128)               0         \n                                                                 \n dense_1 (Dense)             (None, 64)                8256      \n                                                                 \n dropout_1 (Dropout)         (None, 64)                0         \n                                                                 \n dense_2 (Dense)             (None, 32)                2080      \n                                                                 \n dropout_2 (Dropout)         (None, 32)                0         \n                                                                 \n dense_3 (Dense)             (None, 3)                 99        \n                                                                 \n=================================================================\nTotal params: 12487589 (47.64 MB)\nTrainable params: 12487589 (47.64 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(X_train, label_train,\n                    epochs=2,\n                    verbose=True,\n                    validation_data=( X_val, label_val),\n                    batch_size=32)\nloss, accuracy = model.evaluate(X_train, label_train, verbose=True)\nprint(\"Training Accuracy: {:.4f}\".format(accuracy))\nloss_val, accuracy_val = model.evaluate(X_test, label_test, verbose=True)\nprint(\"valadation Accuracy:  {:.4f}\".format(accuracy_val))","metadata":{"execution":{"iopub.status.busy":"2023-12-19T10:50:21.666344Z","iopub.execute_input":"2023-12-19T10:50:21.666767Z","iopub.status.idle":"2023-12-19T11:24:26.661499Z","shell.execute_reply.started":"2023-12-19T10:50:21.666730Z","shell.execute_reply":"2023-12-19T11:24:26.660632Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1/2\n601/601 [==============================] - 928s 2s/step - loss: 0.6433 - accuracy: 0.7564 - val_loss: 0.4712 - val_accuracy: 0.8336\nEpoch 2/2\n601/601 [==============================] - 926s 2s/step - loss: 0.4302 - accuracy: 0.8652 - val_loss: 0.4557 - val_accuracy: 0.8346\n601/601 [==============================] - 117s 194ms/step - loss: 0.3045 - accuracy: 0.8972\nTraining Accuracy: 0.8972\n201/201 [==============================] - 38s 191ms/step - loss: 0.4695 - accuracy: 0.8311\nvaladation Accuracy:  0.8311\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions = model.predict(X_test)\npredicted_labels = np.argmax(predictions, axis=1)\naccuracy = np.mean(predicted_labels == label_test)\nprint(\"Test Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T11:24:26.662762Z","iopub.execute_input":"2023-12-19T11:24:26.663550Z","iopub.status.idle":"2023-12-19T11:25:05.568331Z","shell.execute_reply.started":"2023-12-19T11:24:26.663483Z","shell.execute_reply":"2023-12-19T11:25:05.567192Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"201/201 [==============================] - 39s 190ms/step\nTest Accuracy: 0.8311485642946317\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('model_b32_e100.h5')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T11:25:05.571517Z","iopub.execute_input":"2023-12-19T11:25:05.571947Z","iopub.status.idle":"2023-12-19T11:25:06.001541Z","shell.execute_reply.started":"2023-12-19T11:25:05.571912Z","shell.execute_reply":"2023-12-19T11:25:05.999837Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data=pd.read_csv(\"/kaggle/input/nlp-project/test _no_label.csv\")\n \ntest_data['cleaned_text'] = test_data.review_description.apply(process_review)\n# test_data = test_data[test_data.cleaned_text != \"\"]\n# print(test_data.head(10))\n \nreviews_test=test_data.cleaned_text.values\nX_tokenized_test = [word_tokenize(sentence.lower()) for sentence in reviews_test]\nprint(len(X_tokenized_test))\nX_sequences_test = [[word_index.get(word, 0) for word in sentence] for sentence in X_tokenized_test]\nprint(len(X_sequences_test))\nmaxlen = max(len(seq) for seq in X_sequences)\nreviews_test = pad_sequences(X_sequences_test, padding='post', maxlen=maxlen)\nprint(reviews_test)\npred = model.predict(reviews_test,verbose=True)\npred = np.argmax(pred, axis=1)\nprint(pred)\npred = label_encoder.inverse_transform(pred)\nprint(pred) ","metadata":{"execution":{"iopub.status.busy":"2023-12-19T11:25:06.003404Z","iopub.execute_input":"2023-12-19T11:25:06.003802Z","iopub.status.idle":"2023-12-19T11:25:16.510028Z","shell.execute_reply.started":"2023-12-19T11:25:06.003768Z","shell.execute_reply":"2023-12-19T11:25:16.508693Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"1000\n1000\n[[18730 11293 20782 ...     0     0     0]\n [ 9562 13126 18276 ...     0     0     0]\n [13218 29178  9329 ...     0     0     0]\n ...\n [    0     0     0 ...     0     0     0]\n [26136  9759 24495 ...     0     0     0]\n [28428  6710  9759 ...     0     0     0]]\n32/32 [==============================] - 6s 186ms/step\n[2 2 2 2 2 2 0 0 2 0 2 2 2 0 0 2 2 0 0 0 2 2 2 2 0 0 2 2 2 0 2 0 0 0 0 2 2\n 2 2 2 2 2 2 2 0 0 2 0 2 2 2 2 0 0 0 2 0 0 0 0 2 2 0 0 2 2 0 2 0 0 0 2 2 0\n 0 0 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 0 2 2 0 0 0 0 2 2 0 0 2 2 2\n 2 2 0 2 0 2 2 2 0 2 2 2 2 2 0 2 0 2 2 0 0 2 2 2 0 0 2 2 2 0 0 2 0 2 0 0 2\n 2 2 2 2 2 0 0 0 2 0 2 2 2 2 2 2 0 0 2 2 2 2 2 0 2 2 0 2 2 0 2 0 0 2 2 2 2\n 2 2 2 2 2 2 0 2 2 0 2 0 0 2 2 2 2 2 0 0 2 2 0 2 2 0 0 2 2 0 2 2 0 2 2 2 0\n 0 2 0 2 0 0 0 2 2 2 2 2 2 2 0 0 2 0 0 0 0 2 0 2 2 0 0 2 2 0 0 0 0 2 0 2 2\n 2 2 2 2 2 0 2 0 0 0 2 0 2 2 0 0 0 0 2 2 2 2 2 0 0 0 0 2 2 2 0 2 2 2 2 2 0\n 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 2 2 0 0 2 0 2 2 2 2 2 0 0 2 2\n 2 2 2 0 2 0 2 0 2 2 2 0 2 2 2 2 2 2 0 0 2 0 2 2 2 0 0 2 0 0 0 0 2 2 0 0 0\n 2 0 2 0 0 2 2 0 0 2 2 0 0 0 2 2 2 2 2 0 0 2 2 0 2 0 2 0 0 2 2 2 2 2 0 2 0\n 0 2 2 0 0 0 2 2 0 0 2 2 0 2 2 2 0 2 0 2 0 0 0 0 0 2 2 0 2 2 0 0 2 0 2 2 2\n 0 2 0 2 2 2 0 2 0 0 2 2 0 2 0 2 2 2 2 0 2 2 2 0 2 2 2 2 0 2 2 2 2 2 2 2 2\n 0 2 0 2 0 2 2 2 2 0 0 2 0 0 2 2 2 2 0 0 0 2 2 2 2 2 0 0 0 2 0 2 2 2 0 2 2\n 2 2 0 2 0 2 2 2 0 2 0 0 0 2 2 0 2 0 0 2 2 0 2 2 0 2 2 2 2 0 2 0 0 2 0 2 2\n 2 2 2 2 2 0 0 0 2 2 0 0 0 2 0 0 2 0 2 2 0 2 0 2 0 2 2 2 2 0 2 0 2 2 0 0 0\n 0 0 2 2 2 2 2 2 2 0 2 0 0 2 2 0 2 0 2 2 2 0 0 0 2 2 2 2 2 2 2 0 0 2 0 2 0\n 2 2 2 2 2 2 0 2 2 2 2 0 2 2 2 2 2 2 2 0 2 2 0 2 2 2 0 0 2 0 2 0 2 0 2 2 0\n 0 0 2 0 2 0 2 0 0 2 2 0 0 0 2 2 0 2 2 2 0 0 2 2 2 2 0 0 2 0 2 2 0 2 0 2 2\n 2 2 0 2 2 0 2 2 2 2 2 0 0 2 0 2 0 2 2 2 0 0 0 2 0 2 2 0 2 0 0 0 2 2 0 2 2\n 0 0 2 2 2 2 0 0 2 0 2 0 0 2 0 0 0 2 2 0 2 2 2 2 0 0 0 0 2 0 2 2 2 2 0 2 0\n 2 0 2 2 2 2 2 0 2 2 2 2 2 0 0 2 0 2 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2\n 0 2 0 2 2 2 0 2 0 2 0 2 2 2 2 0 2 0 2 0 0 0 0 2 2 0 2 2 2 2 2 0 2 0 0 2 2\n 2 0 0 0 2 0 2 2 0 0 2 0 0 2 2 2 2 2 2 2 2 0 0 2 2 0 0 2 2 2 2 0 2 2 2 2 2\n 0 2 2 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 0 2 2 0 2 0 2 2 2 2 0 2 2 0 0 2 2 2 0\n 0 2 0 0 2 0 2 0 2 2 0 0 2 2 2 2 2 0 0 0 2 2 2 2 0 2 2 0 0 2 0 0 0 0 2 2 0\n 0 2 0 2 0 0 2 0 0 2 2 2 2 2 0 2 0 2 2 2 2 0 2 0 2 0 2 2 2 2 0 2 2 2 0 2 0\n 0]\n[ 1  1  1  1  1  1 -1 -1  1 -1  1  1  1 -1 -1  1  1 -1 -1 -1  1  1  1  1\n -1 -1  1  1  1 -1  1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1 -1 -1  1 -1\n  1  1  1  1 -1 -1 -1  1 -1 -1 -1 -1  1  1 -1 -1  1  1 -1  1 -1 -1 -1  1\n  1 -1 -1 -1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1\n -1 -1  1  1 -1 -1 -1 -1  1  1 -1 -1  1  1  1  1  1 -1  1 -1  1  1  1 -1\n  1  1  1  1  1 -1  1 -1  1  1 -1 -1  1  1  1 -1 -1  1  1  1 -1 -1  1 -1\n  1 -1 -1  1  1  1  1  1  1 -1 -1 -1  1 -1  1  1  1  1  1  1 -1 -1  1  1\n  1  1  1 -1  1  1 -1  1  1 -1  1 -1 -1  1  1  1  1  1  1  1  1  1  1 -1\n  1  1 -1  1 -1 -1  1  1  1  1  1 -1 -1  1  1 -1  1  1 -1 -1  1  1 -1  1\n  1 -1  1  1  1 -1 -1  1 -1  1 -1 -1 -1  1  1  1  1  1  1  1 -1 -1  1 -1\n -1 -1 -1  1 -1  1  1 -1 -1  1  1 -1 -1 -1 -1  1 -1  1  1  1  1  1  1  1\n -1  1 -1 -1 -1  1 -1  1  1 -1 -1 -1 -1  1  1  1  1  1 -1 -1 -1 -1  1  1\n  1 -1  1  1  1  1  1 -1  1  1  1 -1 -1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1 -1 -1  1  1 -1 -1  1 -1  1  1  1  1  1 -1 -1  1  1  1  1  1\n -1  1 -1  1 -1  1  1  1 -1  1  1  1  1  1  1 -1 -1  1 -1  1  1  1 -1 -1\n  1 -1 -1 -1 -1  1  1 -1 -1 -1  1 -1  1 -1 -1  1  1 -1 -1  1  1 -1 -1 -1\n  1  1  1  1  1 -1 -1  1  1 -1  1 -1  1 -1 -1  1  1  1  1  1 -1  1 -1 -1\n  1  1 -1 -1 -1  1  1 -1 -1  1  1 -1  1  1  1 -1  1 -1  1 -1 -1 -1 -1 -1\n  1  1 -1  1  1 -1 -1  1 -1  1  1  1 -1  1 -1  1  1  1 -1  1 -1 -1  1  1\n -1  1 -1  1  1  1  1 -1  1  1  1 -1  1  1  1  1 -1  1  1  1  1  1  1  1\n  1 -1  1 -1  1 -1  1  1  1  1 -1 -1  1 -1 -1  1  1  1  1 -1 -1 -1  1  1\n  1  1  1 -1 -1 -1  1 -1  1  1  1 -1  1  1  1  1 -1  1 -1  1  1  1 -1  1\n -1 -1 -1  1  1 -1  1 -1 -1  1  1 -1  1  1 -1  1  1  1  1 -1  1 -1 -1  1\n -1  1  1  1  1  1  1  1 -1 -1 -1  1  1 -1 -1 -1  1 -1 -1  1 -1  1  1 -1\n  1 -1  1 -1  1  1  1  1 -1  1 -1  1  1 -1 -1 -1 -1 -1  1  1  1  1  1  1\n  1 -1  1 -1 -1  1  1 -1  1 -1  1  1  1 -1 -1 -1  1  1  1  1  1  1  1 -1\n -1  1 -1  1 -1  1  1  1  1  1  1 -1  1  1  1  1 -1  1  1  1  1  1  1  1\n -1  1  1 -1  1  1  1 -1 -1  1 -1  1 -1  1 -1  1  1 -1 -1 -1  1 -1  1 -1\n  1 -1 -1  1  1 -1 -1 -1  1  1 -1  1  1  1 -1 -1  1  1  1  1 -1 -1  1 -1\n  1  1 -1  1 -1  1  1  1  1 -1  1  1 -1  1  1  1  1  1 -1 -1  1 -1  1 -1\n  1  1  1 -1 -1 -1  1 -1  1  1 -1  1 -1 -1 -1  1  1 -1  1  1 -1 -1  1  1\n  1  1 -1 -1  1 -1  1 -1 -1  1 -1 -1 -1  1  1 -1  1  1  1  1 -1 -1 -1 -1\n  1 -1  1  1  1  1 -1  1 -1  1 -1  1  1  1  1  1 -1  1  1  1  1  1 -1 -1\n  1 -1  1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1 -1  1\n -1  1  1  1 -1  1 -1  1 -1  1  1  1  1 -1  1 -1  1 -1 -1 -1 -1  1  1 -1\n  1  1  1  1  1 -1  1 -1 -1  1  1  1 -1 -1 -1  1 -1  1  1 -1 -1  1 -1 -1\n  1  1  1  1  1  1  1  1 -1 -1  1  1 -1 -1  1  1  1  1 -1  1  1  1  1  1\n -1  1  1  1  1 -1  1  1  1  1  1  1  1 -1  1  1  1  1 -1  1  1 -1  1 -1\n  1  1  1  1 -1  1  1 -1 -1  1  1  1 -1 -1  1 -1 -1  1 -1  1 -1  1  1 -1\n -1  1  1  1  1  1 -1 -1 -1  1  1  1  1 -1  1  1 -1 -1  1 -1 -1 -1 -1  1\n  1 -1 -1  1 -1  1 -1 -1  1 -1 -1  1  1  1  1  1 -1  1 -1  1  1  1  1 -1\n  1 -1  1 -1  1  1  1  1 -1  1  1  1 -1  1 -1 -1]\n","output_type":"stream"}]},{"cell_type":"code","source":"import csv\nwith open('output_predition.csv',mode='w')as out:\n    field=['ID','rating']\n    writer=csv.DictWriter(out,fieldnames=field)\n    writer.writerow({'ID':'ID','rating':'rating'})\n    for i in range(1,1001,1):\n        writer.writerow({'ID':i,'rating':pred[i-1]})","metadata":{"execution":{"iopub.status.busy":"2023-12-19T11:25:16.511983Z","iopub.execute_input":"2023-12-19T11:25:16.512425Z","iopub.status.idle":"2023-12-19T11:25:16.523877Z","shell.execute_reply.started":"2023-12-19T11:25:16.512385Z","shell.execute_reply":"2023-12-19T11:25:16.522338Z"},"trusted":true},"execution_count":12,"outputs":[]}]}