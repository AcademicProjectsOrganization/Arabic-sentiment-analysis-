{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7149868,"sourceType":"datasetVersion","datasetId":4128014},{"sourceId":7156635,"sourceType":"datasetVersion","datasetId":4133082}],"dockerImageVersionId":30615,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nimport nltk\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.backend import clear_session\nfrom keras.models import load_model\n\n\ntrain_data = pd.read_excel(\"/kaggle/input/nlp-project/train.xlsx\")\n\ntrain_data.info()  \n\ntrain_data.columns = ['review_description','rating']\ntrain_data.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-19T10:49:55.126345Z","iopub.execute_input":"2023-12-19T10:49:55.126785Z","iopub.status.idle":"2023-12-19T10:50:14.437821Z","shell.execute_reply.started":"2023-12-19T10:49:55.126749Z","shell.execute_reply":"2023-12-19T10:50:14.436790Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 32036 entries, 0 to 32035\nData columns (total 2 columns):\n #   Column              Non-Null Count  Dtype \n---  ------              --------------  ----- \n 0   review_description  32036 non-null  object\n 1   rating              32036 non-null  int64 \ndtypes: int64(1), object(1)\nmemory usage: 500.7+ KB\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"                                  review_description  rating\n0  Ø´Ø±ÙƒÙ‡ Ø²Ø¨Ø§Ù„Ù‡ Ùˆ Ø³ÙˆØ§Ù‚ÙŠÙ† Ø¨ØªØ¨Ø±Ø´Ù… Ùˆ Ù…ÙÙŠØ´ Ø­ØªÙŠ Ø±Ù‚Ù… Ù„Ù„Ø´Ùƒ...      -1\n1  Ø®Ø¯Ù…Ø© Ø§Ù„Ø¯ÙØ¹ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ù„ÙƒÙŠ Ù†Øª ØªÙˆÙ‚ÙØª Ø¹Ù†Ø¯ÙŠ Ø§ØµØ¨Ø­ ÙÙ‚Ø·...       1\n2  ØªØ·Ø¨ÙŠÙ‚ ØºØ¨ÙŠ Ùˆ Ø¬Ø§Ø±ÙŠ Ø­Ø°ÙÙ‡ ØŒ Ø¹Ø§Ù…Ù„ÙŠÙ† Ø§ÙƒÙˆØ§Ø¯ Ø®ØµÙ… Ùˆ Ù„Ù…Ø§...      -1\n3  ÙØ¹Ù„Ø§ ØªØ·Ø¨ÙŠÙ‚ Ù…Ù…ØªØ§Ø² Ø¨Ø³ Ù„Ùˆ ÙÙ‰ Ø§Ù…ÙƒØ§Ù†ÙŠØ© ÙŠØªÙŠØ­ Ù„Ù…Ø³ØªØ®Ø¯Ù…...       1\n4  Ø³ÙŠØ¡ Ø¬Ø¯Ø§ ØŒ Ø§Ø³Ø¹Ø§Ø± Ø±Ø³ÙˆÙ… Ø§Ù„ØªÙˆØµÙŠÙ„ Ù„Ø§ ØªÙ…Øª Ù„Ù„ÙˆØ§Ù‚Ø¹ Ø¨ Øµ...      -1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_description</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ø´Ø±ÙƒÙ‡ Ø²Ø¨Ø§Ù„Ù‡ Ùˆ Ø³ÙˆØ§Ù‚ÙŠÙ† Ø¨ØªØ¨Ø±Ø´Ù… Ùˆ Ù…ÙÙŠØ´ Ø­ØªÙŠ Ø±Ù‚Ù… Ù„Ù„Ø´Ùƒ...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ø®Ø¯Ù…Ø© Ø§Ù„Ø¯ÙØ¹ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ù„ÙƒÙŠ Ù†Øª ØªÙˆÙ‚ÙØª Ø¹Ù†Ø¯ÙŠ Ø§ØµØ¨Ø­ ÙÙ‚Ø·...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ØªØ·Ø¨ÙŠÙ‚ ØºØ¨ÙŠ Ùˆ Ø¬Ø§Ø±ÙŠ Ø­Ø°ÙÙ‡ ØŒ Ø¹Ø§Ù…Ù„ÙŠÙ† Ø§ÙƒÙˆØ§Ø¯ Ø®ØµÙ… Ùˆ Ù„Ù…Ø§...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ÙØ¹Ù„Ø§ ØªØ·Ø¨ÙŠÙ‚ Ù…Ù…ØªØ§Ø² Ø¨Ø³ Ù„Ùˆ ÙÙ‰ Ø§Ù…ÙƒØ§Ù†ÙŠØ© ÙŠØªÙŠØ­ Ù„Ù…Ø³ØªØ®Ø¯Ù…...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ø³ÙŠØ¡ Ø¬Ø¯Ø§ ØŒ Ø§Ø³Ø¹Ø§Ø± Ø±Ø³ÙˆÙ… Ø§Ù„ØªÙˆØµÙŠÙ„ Ù„Ø§ ØªÙ…Øª Ù„Ù„ÙˆØ§Ù‚Ø¹ Ø¨ Øµ...</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# here we make preprocessing on the data\nimport re\n\nsearch = [\"Ø£\",\"Ø¥\",\"Ø¢\",\"Ø©\",\"_\",\"-\",\"/\",\".\",\"ØŒ\",\" Ùˆ \",\" ÙŠØ§ \",'\"',\"Ù€\",\"'\",\"Ù‰\",\n              \"\\\\\",'\\n', '\\t','\"','?','ØŸ','!']\nreplace = [\"Ø§\",\"Ø§\",\"Ø§\",\"Ù‡\",\" \",\" \",\"\",\"\",\"\",\" Ùˆ\",\" ÙŠØ§\",\n               \"\",\"\",\"\",\"ÙŠ\",\"\",' ', ' ',' ',' ? ',' ØŸ ', ' ! ']\ndef process_review(review):\n    processed_review = re.sub(r\"[^\\w\\s]\", '', review)# accept all things accept any word,digit,white space and replace with empty string\n    processed_review = re.sub(r\"[a-zA-Z]\", '', processed_review) # here I remove all english lettters\n    for i in range(0, len(search)):\n        processed_review = processed_review.replace(search[i], replace[i])\n    processed_review = re.sub(r\"\\d+\", '', processed_review)\n    processed_review = re.sub(r\"\\n\", '', processed_review)# here remove new line\n    processed_review = re.sub(r\"\\s+\", ' ', processed_review)# here remove white spaces\n    processed_review = re.sub(r'(.)\\1+', r'\\1', processed_review)# here if there are any repeate in any character replace it with one occurance\n    \n    return processed_review.strip() # return review after precessed without any additional white space\n\ntrain_data['cleaned_text'] = train_data.review_description.apply(process_review)\n# train_data = train_data[train_data.cleaned_text != \"\"]\ntrain_data.head(10)\n ","metadata":{"execution":{"iopub.status.busy":"2023-12-19T10:50:14.439785Z","iopub.execute_input":"2023-12-19T10:50:14.440520Z","iopub.status.idle":"2023-12-19T10:50:15.288459Z","shell.execute_reply.started":"2023-12-19T10:50:14.440455Z","shell.execute_reply":"2023-12-19T10:50:15.287058Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                  review_description  rating  \\\n0  Ø´Ø±ÙƒÙ‡ Ø²Ø¨Ø§Ù„Ù‡ Ùˆ Ø³ÙˆØ§Ù‚ÙŠÙ† Ø¨ØªØ¨Ø±Ø´Ù… Ùˆ Ù…ÙÙŠØ´ Ø­ØªÙŠ Ø±Ù‚Ù… Ù„Ù„Ø´Ùƒ...      -1   \n1  Ø®Ø¯Ù…Ø© Ø§Ù„Ø¯ÙØ¹ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ù„ÙƒÙŠ Ù†Øª ØªÙˆÙ‚ÙØª Ø¹Ù†Ø¯ÙŠ Ø§ØµØ¨Ø­ ÙÙ‚Ø·...       1   \n2  ØªØ·Ø¨ÙŠÙ‚ ØºØ¨ÙŠ Ùˆ Ø¬Ø§Ø±ÙŠ Ø­Ø°ÙÙ‡ ØŒ Ø¹Ø§Ù…Ù„ÙŠÙ† Ø§ÙƒÙˆØ§Ø¯ Ø®ØµÙ… Ùˆ Ù„Ù…Ø§...      -1   \n3  ÙØ¹Ù„Ø§ ØªØ·Ø¨ÙŠÙ‚ Ù…Ù…ØªØ§Ø² Ø¨Ø³ Ù„Ùˆ ÙÙ‰ Ø§Ù…ÙƒØ§Ù†ÙŠØ© ÙŠØªÙŠØ­ Ù„Ù…Ø³ØªØ®Ø¯Ù…...       1   \n4  Ø³ÙŠØ¡ Ø¬Ø¯Ø§ ØŒ Ø§Ø³Ø¹Ø§Ø± Ø±Ø³ÙˆÙ… Ø§Ù„ØªÙˆØµÙŠÙ„ Ù„Ø§ ØªÙ…Øª Ù„Ù„ÙˆØ§Ù‚Ø¹ Ø¨ Øµ...      -1   \n5  Ù‚Ø¹Ø¯ Ø¹Ø´Ø±ÙŠÙ† Ø³Ù†Ø© ÙŠØ¯ÙˆØ± Ø¹Ù„Ù‰ Ø³Ø§Ø¦Ù‚ Ø¨Ø³ Ø§Ù…Ø§ Ø¹Ù† ØªÙˆØµÙŠÙ„ Ø§Ù„...       0   \n6                                         Ø§Ø­Ù„Ø¦ ØªØ·Ø¨ÙŠÙ‚       1   \n7                                      Ø±Ø§Ø¦Ø¹ ÙˆØ§Ùˆ Ù…Ø¯Ù‡Ø´       1   \n8  Ù…Ú©Ùˆ Ø¨Ø³ Ø§Ù„Ø¨Ø­Ø±ÛŒÙ† ÙˆØ¹Ù…Ø§Ù† ÙˆØºÛŒØ±Ù‡Ù‡ Ø¨Ø³ Ø§Ù„Ø¹Ø±Ø§Ù‚ Ù…Ú©Ùˆ ÛŒØ¹Ù†ÛŒ...      -1   \n9                    ØªØ·Ø¨ÙŠÙ‚ Ø¬Ù…ÙŠÙ„ ÙŠØ³ØªØ§Ù‡Ù„ Ø§Ù„Ø®Ù…Ø³ Ù†Ø¬ÙˆÙ…ğŸ‘ğŸ‘ğŸ‘       1   \n\n                                        cleaned_text  \n0  Ø´Ø±ÙƒÙ‡ Ø²Ø¨Ø§Ù„Ù‡ ÙˆØ³ÙˆØ§Ù‚ÙŠÙ† Ø¨ØªØ¨Ø±Ø´Ù… ÙˆÙ…ÙÙŠØ´ Ø­ØªÙŠ Ø±Ù‚Ù… Ù„Ø´ÙƒØ§ÙˆÙŠ...  \n1  Ø®Ø¯Ù…Ù‡ Ø§Ù„Ø¯ÙØ¹ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ù„ÙƒÙŠ Ù†Øª ØªÙˆÙ‚ÙØª Ø¹Ù†Ø¯ÙŠ Ø§ØµØ¨Ø­ ÙÙ‚Ø·...  \n2  ØªØ·Ø¨ÙŠÙ‚ ØºØ¨ÙŠ ÙˆØ¬Ø§Ø±ÙŠ Ø­Ø°ÙÙ‡ Ø¹Ø§Ù…Ù„ÙŠÙ† Ø§ÙƒÙˆØ§Ø¯ Ø®ØµÙ… ÙˆÙ„Ù…Ø§ Ù†Ø³Øª...  \n3  ÙØ¹Ù„Ø§ ØªØ·Ø¨ÙŠÙ‚ Ù…ØªØ§Ø² Ø¨Ø³ Ù„Ùˆ ÙÙŠ Ø§Ù…ÙƒØ§Ù†ÙŠÙ‡ ÙŠØªÙŠØ­ Ù„Ù…Ø³ØªØ®Ø¯Ù… ...  \n4      Ø³ÙŠØ¡ Ø¬Ø¯Ø§ Ø§Ø³Ø¹Ø§Ø± Ø±Ø³ÙˆÙ… Ø§Ù„ØªÙˆØµÙŠÙ„ Ù„Ø§ ØªÙ…Øª Ù„ÙˆØ§Ù‚Ø¹ Ø¨ ØµÙ„Ù‡  \n5  Ù‚Ø¹Ø¯ Ø¹Ø´Ø±ÙŠÙ† Ø³Ù†Ù‡ ÙŠØ¯ÙˆØ± Ø¹Ù„ÙŠ Ø³Ø§Ø¦Ù‚ Ø¨Ø³ Ø§Ù…Ø§ Ø¹Ù† ØªÙˆØµÙŠÙ„ Ø§Ù„...  \n6                                         Ø§Ø­Ù„Ø¦ ØªØ·Ø¨ÙŠÙ‚  \n7                                      Ø±Ø§Ø¦Ø¹ ÙˆØ§Ùˆ Ù…Ø¯Ù‡Ø´  \n8  Ù…Ú©Ùˆ Ø¨Ø³ Ø§Ù„Ø¨Ø­Ø±ÛŒÙ† ÙˆØ¹Ù…Ø§Ù† ÙˆØºÛŒØ±Ù‡ Ø¨Ø³ Ø§Ù„Ø¹Ø±Ø§Ù‚ Ù…Ú©Ùˆ ÛŒØ¹Ù†ÛŒ ...  \n9                       ØªØ·Ø¨ÙŠÙ‚ Ø¬Ù…ÙŠÙ„ ÙŠØ³ØªØ§Ù‡Ù„ Ø§Ù„Ø®Ù…Ø³ Ù†Ø¬ÙˆÙ…  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_description</th>\n      <th>rating</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ø´Ø±ÙƒÙ‡ Ø²Ø¨Ø§Ù„Ù‡ Ùˆ Ø³ÙˆØ§Ù‚ÙŠÙ† Ø¨ØªØ¨Ø±Ø´Ù… Ùˆ Ù…ÙÙŠØ´ Ø­ØªÙŠ Ø±Ù‚Ù… Ù„Ù„Ø´Ùƒ...</td>\n      <td>-1</td>\n      <td>Ø´Ø±ÙƒÙ‡ Ø²Ø¨Ø§Ù„Ù‡ ÙˆØ³ÙˆØ§Ù‚ÙŠÙ† Ø¨ØªØ¨Ø±Ø´Ù… ÙˆÙ…ÙÙŠØ´ Ø­ØªÙŠ Ø±Ù‚Ù… Ù„Ø´ÙƒØ§ÙˆÙŠ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ø®Ø¯Ù…Ø© Ø§Ù„Ø¯ÙØ¹ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ù„ÙƒÙŠ Ù†Øª ØªÙˆÙ‚ÙØª Ø¹Ù†Ø¯ÙŠ Ø§ØµØ¨Ø­ ÙÙ‚Ø·...</td>\n      <td>1</td>\n      <td>Ø®Ø¯Ù…Ù‡ Ø§Ù„Ø¯ÙØ¹ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ù„ÙƒÙŠ Ù†Øª ØªÙˆÙ‚ÙØª Ø¹Ù†Ø¯ÙŠ Ø§ØµØ¨Ø­ ÙÙ‚Ø·...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ØªØ·Ø¨ÙŠÙ‚ ØºØ¨ÙŠ Ùˆ Ø¬Ø§Ø±ÙŠ Ø­Ø°ÙÙ‡ ØŒ Ø¹Ø§Ù…Ù„ÙŠÙ† Ø§ÙƒÙˆØ§Ø¯ Ø®ØµÙ… Ùˆ Ù„Ù…Ø§...</td>\n      <td>-1</td>\n      <td>ØªØ·Ø¨ÙŠÙ‚ ØºØ¨ÙŠ ÙˆØ¬Ø§Ø±ÙŠ Ø­Ø°ÙÙ‡ Ø¹Ø§Ù…Ù„ÙŠÙ† Ø§ÙƒÙˆØ§Ø¯ Ø®ØµÙ… ÙˆÙ„Ù…Ø§ Ù†Ø³Øª...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ÙØ¹Ù„Ø§ ØªØ·Ø¨ÙŠÙ‚ Ù…Ù…ØªØ§Ø² Ø¨Ø³ Ù„Ùˆ ÙÙ‰ Ø§Ù…ÙƒØ§Ù†ÙŠØ© ÙŠØªÙŠØ­ Ù„Ù…Ø³ØªØ®Ø¯Ù…...</td>\n      <td>1</td>\n      <td>ÙØ¹Ù„Ø§ ØªØ·Ø¨ÙŠÙ‚ Ù…ØªØ§Ø² Ø¨Ø³ Ù„Ùˆ ÙÙŠ Ø§Ù…ÙƒØ§Ù†ÙŠÙ‡ ÙŠØªÙŠØ­ Ù„Ù…Ø³ØªØ®Ø¯Ù… ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ø³ÙŠØ¡ Ø¬Ø¯Ø§ ØŒ Ø§Ø³Ø¹Ø§Ø± Ø±Ø³ÙˆÙ… Ø§Ù„ØªÙˆØµÙŠÙ„ Ù„Ø§ ØªÙ…Øª Ù„Ù„ÙˆØ§Ù‚Ø¹ Ø¨ Øµ...</td>\n      <td>-1</td>\n      <td>Ø³ÙŠØ¡ Ø¬Ø¯Ø§ Ø§Ø³Ø¹Ø§Ø± Ø±Ø³ÙˆÙ… Ø§Ù„ØªÙˆØµÙŠÙ„ Ù„Ø§ ØªÙ…Øª Ù„ÙˆØ§Ù‚Ø¹ Ø¨ ØµÙ„Ù‡</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Ù‚Ø¹Ø¯ Ø¹Ø´Ø±ÙŠÙ† Ø³Ù†Ø© ÙŠØ¯ÙˆØ± Ø¹Ù„Ù‰ Ø³Ø§Ø¦Ù‚ Ø¨Ø³ Ø§Ù…Ø§ Ø¹Ù† ØªÙˆØµÙŠÙ„ Ø§Ù„...</td>\n      <td>0</td>\n      <td>Ù‚Ø¹Ø¯ Ø¹Ø´Ø±ÙŠÙ† Ø³Ù†Ù‡ ÙŠØ¯ÙˆØ± Ø¹Ù„ÙŠ Ø³Ø§Ø¦Ù‚ Ø¨Ø³ Ø§Ù…Ø§ Ø¹Ù† ØªÙˆØµÙŠÙ„ Ø§Ù„...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Ø§Ø­Ù„Ø¦ ØªØ·Ø¨ÙŠÙ‚</td>\n      <td>1</td>\n      <td>Ø§Ø­Ù„Ø¦ ØªØ·Ø¨ÙŠÙ‚</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Ø±Ø§Ø¦Ø¹ ÙˆØ§Ùˆ Ù…Ø¯Ù‡Ø´</td>\n      <td>1</td>\n      <td>Ø±Ø§Ø¦Ø¹ ÙˆØ§Ùˆ Ù…Ø¯Ù‡Ø´</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Ù…Ú©Ùˆ Ø¨Ø³ Ø§Ù„Ø¨Ø­Ø±ÛŒÙ† ÙˆØ¹Ù…Ø§Ù† ÙˆØºÛŒØ±Ù‡Ù‡ Ø¨Ø³ Ø§Ù„Ø¹Ø±Ø§Ù‚ Ù…Ú©Ùˆ ÛŒØ¹Ù†ÛŒ...</td>\n      <td>-1</td>\n      <td>Ù…Ú©Ùˆ Ø¨Ø³ Ø§Ù„Ø¨Ø­Ø±ÛŒÙ† ÙˆØ¹Ù…Ø§Ù† ÙˆØºÛŒØ±Ù‡ Ø¨Ø³ Ø§Ù„Ø¹Ø±Ø§Ù‚ Ù…Ú©Ùˆ ÛŒØ¹Ù†ÛŒ ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ØªØ·Ø¨ÙŠÙ‚ Ø¬Ù…ÙŠÙ„ ÙŠØ³ØªØ§Ù‡Ù„ Ø§Ù„Ø®Ù…Ø³ Ù†Ø¬ÙˆÙ…ğŸ‘ğŸ‘ğŸ‘</td>\n      <td>1</td>\n      <td>ØªØ·Ø¨ÙŠÙ‚ Ø¬Ù…ÙŠÙ„ ÙŠØ³ØªØ§Ù‡Ù„ Ø§Ù„Ø®Ù…Ø³ Ù†Ø¬ÙˆÙ…</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nX = train_data.cleaned_text.values #training paramter\nY = train_data['rating'].astype('int') #prediction paramter\n# Y = Y.clip(0, 1)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T10:50:15.289725Z","iopub.execute_input":"2023-12-19T10:50:15.290070Z","iopub.status.idle":"2023-12-19T10:50:15.297435Z","shell.execute_reply.started":"2023-12-19T10:50:15.290041Z","shell.execute_reply":"2023-12-19T10:50:15.296289Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from nltk.tokenize import WordPunctTokenizer \nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom nltk import word_tokenize  \ntokenizer = WordPunctTokenizer()\nX_tokenized = [word_tokenize(sentence.lower()) for sentence in X]\nword_index = {word: index + 1 for index, word in enumerate(set(word_tokenize(\" \".join(X))))}\nX_sequences = [[word_index.get(word, 0) for word in sentence] for sentence in X_tokenized]\nmaxlen = max(len(seq) for seq in X_sequences)\nprint(maxlen)\nX_padded = pad_sequences(X_sequences, padding='post', maxlen=maxlen)\nX=X_padded  \nprint(X)\nprint(\"Vocabulary size:\", len(word_index))\nprint(X.shape[1])\n# print(len(X))","metadata":{"execution":{"iopub.status.busy":"2023-12-19T10:50:15.300791Z","iopub.execute_input":"2023-12-19T10:50:15.301143Z","iopub.status.idle":"2023-12-19T10:50:20.730834Z","shell.execute_reply.started":"2023-12-19T10:50:15.301113Z","shell.execute_reply":"2023-12-19T10:50:20.729229Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"362\n[[10326  6131   226 ...     0     0     0]\n [20782  2596 19179 ...     0     0     0]\n [26136  2237 27874 ...     0     0     0]\n ...\n [29994 29479 26410 ...     0     0     0]\n [26136 26221 26396 ...     0     0     0]\n [29811 16509 20971 ...     0     0     0]]\nVocabulary size: 33372\n362\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\nY= label_encoder.fit_transform(Y)\nprint(Y)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T10:50:20.732527Z","iopub.execute_input":"2023-12-19T10:50:20.732957Z","iopub.status.idle":"2023-12-19T10:50:20.743766Z","shell.execute_reply.started":"2023-12-19T10:50:20.732922Z","shell.execute_reply":"2023-12-19T10:50:20.741806Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[0 2 0 ... 0 0 2]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, label_train, label_val = train_test_split(X , Y, test_size=0.4, random_state=42)\nX_val,X_test,label_val,label_test = train_test_split( X_val , label_val, test_size=0.5, random_state=42)\nprint(\"Training:\", len(X_train))\nprint(\"valadation\",len(X_val))\nprint(\"Testing: \", len(X_test))","metadata":{"execution":{"iopub.status.busy":"2023-12-19T10:50:20.745264Z","iopub.execute_input":"2023-12-19T10:50:20.745847Z","iopub.status.idle":"2023-12-19T10:50:20.824063Z","shell.execute_reply.started":"2023-12-19T10:50:20.745783Z","shell.execute_reply":"2023-12-19T10:50:20.822936Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Training: 19221\nvaladation 6407\nTesting:  6408\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":" \nembedding_dim = 100\ndropout = 0.5\nopt = 'adam'\nclear_session()\nmodel = Sequential()\nmodel.add(layers.Embedding(input_dim=33373, \n                           output_dim=362, \n                           input_length=362))\nmodel.add(layers.Bidirectional(layers.LSTM(100, dropout=0.5, \n                                           recurrent_dropout=0.5, \n                                           return_sequences=True)))\nmodel.add(layers.GlobalMaxPool1D())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(dropout))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dropout(dropout))\nmodel.add(layers.Dense(32, activation='relu'))\nmodel.add(layers.Dropout(dropout))\nmodel.add(layers.Dense(3, activation='softmax'))\n\nmodel.compile(optimizer=opt, \n              loss='sparse_categorical_crossentropy', \n              metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T10:50:20.825842Z","iopub.execute_input":"2023-12-19T10:50:20.826248Z","iopub.status.idle":"2023-12-19T10:50:21.664860Z","shell.execute_reply.started":"2023-12-19T10:50:20.826210Z","shell.execute_reply":"2023-12-19T10:50:21.663636Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 362, 362)          12081026  \n                                                                 \n bidirectional (Bidirection  (None, 362, 200)          370400    \n al)                                                             \n                                                                 \n global_max_pooling1d (Glob  (None, 200)               0         \n alMaxPooling1D)                                                 \n                                                                 \n dense (Dense)               (None, 128)               25728     \n                                                                 \n dropout (Dropout)           (None, 128)               0         \n                                                                 \n dense_1 (Dense)             (None, 64)                8256      \n                                                                 \n dropout_1 (Dropout)         (None, 64)                0         \n                                                                 \n dense_2 (Dense)             (None, 32)                2080      \n                                                                 \n dropout_2 (Dropout)         (None, 32)                0         \n                                                                 \n dense_3 (Dense)             (None, 3)                 99        \n                                                                 \n=================================================================\nTotal params: 12487589 (47.64 MB)\nTrainable params: 12487589 (47.64 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(X_train, label_train,\n                    epochs=2,\n                    verbose=True,\n                    validation_data=( X_val, label_val),\n                    batch_size=32)\nloss, accuracy = model.evaluate(X_train, label_train, verbose=True)\nprint(\"Training Accuracy: {:.4f}\".format(accuracy))\nloss_val, accuracy_val = model.evaluate(X_test, label_test, verbose=True)\nprint(\"valadation Accuracy:  {:.4f}\".format(accuracy_val))","metadata":{"execution":{"iopub.status.busy":"2023-12-19T10:50:21.666344Z","iopub.execute_input":"2023-12-19T10:50:21.666767Z","iopub.status.idle":"2023-12-19T11:24:26.661499Z","shell.execute_reply.started":"2023-12-19T10:50:21.666730Z","shell.execute_reply":"2023-12-19T11:24:26.660632Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1/2\n601/601 [==============================] - 928s 2s/step - loss: 0.6433 - accuracy: 0.7564 - val_loss: 0.4712 - val_accuracy: 0.8336\nEpoch 2/2\n601/601 [==============================] - 926s 2s/step - loss: 0.4302 - accuracy: 0.8652 - val_loss: 0.4557 - val_accuracy: 0.8346\n601/601 [==============================] - 117s 194ms/step - loss: 0.3045 - accuracy: 0.8972\nTraining Accuracy: 0.8972\n201/201 [==============================] - 38s 191ms/step - loss: 0.4695 - accuracy: 0.8311\nvaladation Accuracy:  0.8311\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions = model.predict(X_test)\npredicted_labels = np.argmax(predictions, axis=1)\naccuracy = np.mean(predicted_labels == label_test)\nprint(\"Test Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T11:24:26.662762Z","iopub.execute_input":"2023-12-19T11:24:26.663550Z","iopub.status.idle":"2023-12-19T11:25:05.568331Z","shell.execute_reply.started":"2023-12-19T11:24:26.663483Z","shell.execute_reply":"2023-12-19T11:25:05.567192Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"201/201 [==============================] - 39s 190ms/step\nTest Accuracy: 0.8311485642946317\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('model_b32_e100.h5')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T11:25:05.571517Z","iopub.execute_input":"2023-12-19T11:25:05.571947Z","iopub.status.idle":"2023-12-19T11:25:06.001541Z","shell.execute_reply.started":"2023-12-19T11:25:05.571912Z","shell.execute_reply":"2023-12-19T11:25:05.999837Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data=pd.read_csv(\"/kaggle/input/nlp-project/test _no_label.csv\")\n \ntest_data['cleaned_text'] = test_data.review_description.apply(process_review)\n# test_data = test_data[test_data.cleaned_text != \"\"]\n# print(test_data.head(10))\n \nreviews_test=test_data.cleaned_text.values\nX_tokenized_test = [word_tokenize(sentence.lower()) for sentence in reviews_test]\nprint(len(X_tokenized_test))\nX_sequences_test = [[word_index.get(word, 0) for word in sentence] for sentence in X_tokenized_test]\nprint(len(X_sequences_test))\nmaxlen = max(len(seq) for seq in X_sequences)\nreviews_test = pad_sequences(X_sequences_test, padding='post', maxlen=maxlen)\nprint(reviews_test)\npred = model.predict(reviews_test,verbose=True)\npred = np.argmax(pred, axis=1)\nprint(pred)\npred = label_encoder.inverse_transform(pred)\nprint(pred) ","metadata":{"execution":{"iopub.status.busy":"2023-12-19T11:25:06.003404Z","iopub.execute_input":"2023-12-19T11:25:06.003802Z","iopub.status.idle":"2023-12-19T11:25:16.510028Z","shell.execute_reply.started":"2023-12-19T11:25:06.003768Z","shell.execute_reply":"2023-12-19T11:25:16.508693Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"1000\n1000\n[[18730 11293 20782 ...     0     0     0]\n [ 9562 13126 18276 ...     0     0     0]\n [13218 29178  9329 ...     0     0     0]\n ...\n [    0     0     0 ...     0     0     0]\n [26136  9759 24495 ...     0     0     0]\n [28428  6710  9759 ...     0     0     0]]\n32/32 [==============================] - 6s 186ms/step\n[2 2 2 2 2 2 0 0 2 0 2 2 2 0 0 2 2 0 0 0 2 2 2 2 0 0 2 2 2 0 2 0 0 0 0 2 2\n 2 2 2 2 2 2 2 0 0 2 0 2 2 2 2 0 0 0 2 0 0 0 0 2 2 0 0 2 2 0 2 0 0 0 2 2 0\n 0 0 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 0 2 2 0 0 0 0 2 2 0 0 2 2 2\n 2 2 0 2 0 2 2 2 0 2 2 2 2 2 0 2 0 2 2 0 0 2 2 2 0 0 2 2 2 0 0 2 0 2 0 0 2\n 2 2 2 2 2 0 0 0 2 0 2 2 2 2 2 2 0 0 2 2 2 2 2 0 2 2 0 2 2 0 2 0 0 2 2 2 2\n 2 2 2 2 2 2 0 2 2 0 2 0 0 2 2 2 2 2 0 0 2 2 0 2 2 0 0 2 2 0 2 2 0 2 2 2 0\n 0 2 0 2 0 0 0 2 2 2 2 2 2 2 0 0 2 0 0 0 0 2 0 2 2 0 0 2 2 0 0 0 0 2 0 2 2\n 2 2 2 2 2 0 2 0 0 0 2 0 2 2 0 0 0 0 2 2 2 2 2 0 0 0 0 2 2 2 0 2 2 2 2 2 0\n 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 2 2 0 0 2 0 2 2 2 2 2 0 0 2 2\n 2 2 2 0 2 0 2 0 2 2 2 0 2 2 2 2 2 2 0 0 2 0 2 2 2 0 0 2 0 0 0 0 2 2 0 0 0\n 2 0 2 0 0 2 2 0 0 2 2 0 0 0 2 2 2 2 2 0 0 2 2 0 2 0 2 0 0 2 2 2 2 2 0 2 0\n 0 2 2 0 0 0 2 2 0 0 2 2 0 2 2 2 0 2 0 2 0 0 0 0 0 2 2 0 2 2 0 0 2 0 2 2 2\n 0 2 0 2 2 2 0 2 0 0 2 2 0 2 0 2 2 2 2 0 2 2 2 0 2 2 2 2 0 2 2 2 2 2 2 2 2\n 0 2 0 2 0 2 2 2 2 0 0 2 0 0 2 2 2 2 0 0 0 2 2 2 2 2 0 0 0 2 0 2 2 2 0 2 2\n 2 2 0 2 0 2 2 2 0 2 0 0 0 2 2 0 2 0 0 2 2 0 2 2 0 2 2 2 2 0 2 0 0 2 0 2 2\n 2 2 2 2 2 0 0 0 2 2 0 0 0 2 0 0 2 0 2 2 0 2 0 2 0 2 2 2 2 0 2 0 2 2 0 0 0\n 0 0 2 2 2 2 2 2 2 0 2 0 0 2 2 0 2 0 2 2 2 0 0 0 2 2 2 2 2 2 2 0 0 2 0 2 0\n 2 2 2 2 2 2 0 2 2 2 2 0 2 2 2 2 2 2 2 0 2 2 0 2 2 2 0 0 2 0 2 0 2 0 2 2 0\n 0 0 2 0 2 0 2 0 0 2 2 0 0 0 2 2 0 2 2 2 0 0 2 2 2 2 0 0 2 0 2 2 0 2 0 2 2\n 2 2 0 2 2 0 2 2 2 2 2 0 0 2 0 2 0 2 2 2 0 0 0 2 0 2 2 0 2 0 0 0 2 2 0 2 2\n 0 0 2 2 2 2 0 0 2 0 2 0 0 2 0 0 0 2 2 0 2 2 2 2 0 0 0 0 2 0 2 2 2 2 0 2 0\n 2 0 2 2 2 2 2 0 2 2 2 2 2 0 0 2 0 2 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2\n 0 2 0 2 2 2 0 2 0 2 0 2 2 2 2 0 2 0 2 0 0 0 0 2 2 0 2 2 2 2 2 0 2 0 0 2 2\n 2 0 0 0 2 0 2 2 0 0 2 0 0 2 2 2 2 2 2 2 2 0 0 2 2 0 0 2 2 2 2 0 2 2 2 2 2\n 0 2 2 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 0 2 2 0 2 0 2 2 2 2 0 2 2 0 0 2 2 2 0\n 0 2 0 0 2 0 2 0 2 2 0 0 2 2 2 2 2 0 0 0 2 2 2 2 0 2 2 0 0 2 0 0 0 0 2 2 0\n 0 2 0 2 0 0 2 0 0 2 2 2 2 2 0 2 0 2 2 2 2 0 2 0 2 0 2 2 2 2 0 2 2 2 0 2 0\n 0]\n[ 1  1  1  1  1  1 -1 -1  1 -1  1  1  1 -1 -1  1  1 -1 -1 -1  1  1  1  1\n -1 -1  1  1  1 -1  1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1 -1 -1  1 -1\n  1  1  1  1 -1 -1 -1  1 -1 -1 -1 -1  1  1 -1 -1  1  1 -1  1 -1 -1 -1  1\n  1 -1 -1 -1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1\n -1 -1  1  1 -1 -1 -1 -1  1  1 -1 -1  1  1  1  1  1 -1  1 -1  1  1  1 -1\n  1  1  1  1  1 -1  1 -1  1  1 -1 -1  1  1  1 -1 -1  1  1  1 -1 -1  1 -1\n  1 -1 -1  1  1  1  1  1  1 -1 -1 -1  1 -1  1  1  1  1  1  1 -1 -1  1  1\n  1  1  1 -1  1  1 -1  1  1 -1  1 -1 -1  1  1  1  1  1  1  1  1  1  1 -1\n  1  1 -1  1 -1 -1  1  1  1  1  1 -1 -1  1  1 -1  1  1 -1 -1  1  1 -1  1\n  1 -1  1  1  1 -1 -1  1 -1  1 -1 -1 -1  1  1  1  1  1  1  1 -1 -1  1 -1\n -1 -1 -1  1 -1  1  1 -1 -1  1  1 -1 -1 -1 -1  1 -1  1  1  1  1  1  1  1\n -1  1 -1 -1 -1  1 -1  1  1 -1 -1 -1 -1  1  1  1  1  1 -1 -1 -1 -1  1  1\n  1 -1  1  1  1  1  1 -1  1  1  1 -1 -1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1 -1 -1  1  1 -1 -1  1 -1  1  1  1  1  1 -1 -1  1  1  1  1  1\n -1  1 -1  1 -1  1  1  1 -1  1  1  1  1  1  1 -1 -1  1 -1  1  1  1 -1 -1\n  1 -1 -1 -1 -1  1  1 -1 -1 -1  1 -1  1 -1 -1  1  1 -1 -1  1  1 -1 -1 -1\n  1  1  1  1  1 -1 -1  1  1 -1  1 -1  1 -1 -1  1  1  1  1  1 -1  1 -1 -1\n  1  1 -1 -1 -1  1  1 -1 -1  1  1 -1  1  1  1 -1  1 -1  1 -1 -1 -1 -1 -1\n  1  1 -1  1  1 -1 -1  1 -1  1  1  1 -1  1 -1  1  1  1 -1  1 -1 -1  1  1\n -1  1 -1  1  1  1  1 -1  1  1  1 -1  1  1  1  1 -1  1  1  1  1  1  1  1\n  1 -1  1 -1  1 -1  1  1  1  1 -1 -1  1 -1 -1  1  1  1  1 -1 -1 -1  1  1\n  1  1  1 -1 -1 -1  1 -1  1  1  1 -1  1  1  1  1 -1  1 -1  1  1  1 -1  1\n -1 -1 -1  1  1 -1  1 -1 -1  1  1 -1  1  1 -1  1  1  1  1 -1  1 -1 -1  1\n -1  1  1  1  1  1  1  1 -1 -1 -1  1  1 -1 -1 -1  1 -1 -1  1 -1  1  1 -1\n  1 -1  1 -1  1  1  1  1 -1  1 -1  1  1 -1 -1 -1 -1 -1  1  1  1  1  1  1\n  1 -1  1 -1 -1  1  1 -1  1 -1  1  1  1 -1 -1 -1  1  1  1  1  1  1  1 -1\n -1  1 -1  1 -1  1  1  1  1  1  1 -1  1  1  1  1 -1  1  1  1  1  1  1  1\n -1  1  1 -1  1  1  1 -1 -1  1 -1  1 -1  1 -1  1  1 -1 -1 -1  1 -1  1 -1\n  1 -1 -1  1  1 -1 -1 -1  1  1 -1  1  1  1 -1 -1  1  1  1  1 -1 -1  1 -1\n  1  1 -1  1 -1  1  1  1  1 -1  1  1 -1  1  1  1  1  1 -1 -1  1 -1  1 -1\n  1  1  1 -1 -1 -1  1 -1  1  1 -1  1 -1 -1 -1  1  1 -1  1  1 -1 -1  1  1\n  1  1 -1 -1  1 -1  1 -1 -1  1 -1 -1 -1  1  1 -1  1  1  1  1 -1 -1 -1 -1\n  1 -1  1  1  1  1 -1  1 -1  1 -1  1  1  1  1  1 -1  1  1  1  1  1 -1 -1\n  1 -1  1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1 -1  1\n -1  1  1  1 -1  1 -1  1 -1  1  1  1  1 -1  1 -1  1 -1 -1 -1 -1  1  1 -1\n  1  1  1  1  1 -1  1 -1 -1  1  1  1 -1 -1 -1  1 -1  1  1 -1 -1  1 -1 -1\n  1  1  1  1  1  1  1  1 -1 -1  1  1 -1 -1  1  1  1  1 -1  1  1  1  1  1\n -1  1  1  1  1 -1  1  1  1  1  1  1  1 -1  1  1  1  1 -1  1  1 -1  1 -1\n  1  1  1  1 -1  1  1 -1 -1  1  1  1 -1 -1  1 -1 -1  1 -1  1 -1  1  1 -1\n -1  1  1  1  1  1 -1 -1 -1  1  1  1  1 -1  1  1 -1 -1  1 -1 -1 -1 -1  1\n  1 -1 -1  1 -1  1 -1 -1  1 -1 -1  1  1  1  1  1 -1  1 -1  1  1  1  1 -1\n  1 -1  1 -1  1  1  1  1 -1  1  1  1 -1  1 -1 -1]\n","output_type":"stream"}]},{"cell_type":"code","source":"import csv\nwith open('output_predition.csv',mode='w')as out:\n    field=['ID','rating']\n    writer=csv.DictWriter(out,fieldnames=field)\n    writer.writerow({'ID':'ID','rating':'rating'})\n    for i in range(1,1001,1):\n        writer.writerow({'ID':i,'rating':pred[i-1]})","metadata":{"execution":{"iopub.status.busy":"2023-12-19T11:25:16.511983Z","iopub.execute_input":"2023-12-19T11:25:16.512425Z","iopub.status.idle":"2023-12-19T11:25:16.523877Z","shell.execute_reply.started":"2023-12-19T11:25:16.512385Z","shell.execute_reply":"2023-12-19T11:25:16.522338Z"},"trusted":true},"execution_count":12,"outputs":[]}]}